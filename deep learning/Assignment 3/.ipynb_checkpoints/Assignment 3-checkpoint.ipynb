{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Character-Level Recurrent Neural Network by PyTorch\n",
    "\n",
    "In this assignment, you are required to implement Character-Level RNN just as we have learned in the class. However, the difference is we use another dataset in this assignment.\n",
    "\n",
    "Read through the tutorial [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) that builds a char-rnn that is used to classify names by their country of origin, which is introduced in the class. It is recommended that you can reproduce the tutorialâ€™s results on the provided name dataset before moving on (notebook for Lecture 7), since the neural network architectures remain largely the same. Make sure you try your best to understand the dimensions of each layer (e.g. which ones can stay the same, and which are hyperparameters for us to tweak).\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Code implementation. (20 marks)\n",
    "2. Experimentation and analysis (80 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNS4OZXxMZ-A"
   },
   "outputs": [],
   "source": [
    "#Download and unzip files\n",
    "!pip3 install scikit-learn\n",
    "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_test.txt\n",
    "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_val.zip\n",
    "!wget http://computational-linguistics-class.org/homework/nn-lms/cities_train.zip\n",
    "!sudo apt-get install unzip\n",
    "!unzip cities_val.zip \n",
    "!unzip cities_train.zip \n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install torch torchvision\n",
    "  \n",
    "import torch\n",
    "device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qIJxbqMDNTTl"
   },
   "outputs": [],
   "source": [
    "#Verfiy file download\n",
    "!head train/af.txt\n",
    "!printf \"\\n\"\n",
    "!head val/af.txt\n",
    "!printf \"\\n\"\n",
    "!head cities_test.txt\n",
    "!printf \"\\n\"\n",
    "#Verify CUDA acceleration should print cuda:0\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Implementation (20 marks)\n",
    "\n",
    "**You should implement all the following functions and you are not allowed to delete any of them. Of course you can add more functions based on this skeleton.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kwB5RzvfOGr_"
   },
   "outputs": [],
   "source": [
    "#main_classify.py\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "'''\n",
    "Don't change these constants for the classification task.\n",
    "You may use different copies for the sentence generation model.\n",
    "'''\n",
    "languages = [\"af\", \"cn\", \"de\", \"fi\", \"fr\", \"in\", \"ir\", \"pk\", \"za\"]\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "\n",
    "'''\n",
    "Returns the words of the language specified by reading it from the data folder\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "Return: A nx1 array containing the words of the specified language\n",
    "'''\n",
    "def getWords(baseDir, lang, train = True):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Returns a label corresponding to the language\n",
    "For example it returns an array of 0s for af\n",
    "Return: A nx1 array as integers containing index of the specified language in the \"languages\" array\n",
    "'''\n",
    "def getLabels(lang, length):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Returns all the laguages and labels after reading it from the file\n",
    "Returns the validation data if train is false and the train data otherwise.\n",
    "You may assume that the files exist in baseDir and have the same names.\n",
    "Return: X, y where X is nx1 and y is nx1\n",
    "'''\n",
    "def readData(baseDir, train=True):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Convert a line/word to a pytorch tensor of numbers\n",
    "Refer the tutorial in the spec\n",
    "Return: A tensor corresponding to the given line\n",
    "'''\n",
    "def line_to_tensor(line):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Returns the category/class of the output from the neural network\n",
    "Input: Output of the neural networks (class probabilities)\n",
    "Return: A tuple with (language, language_index)\n",
    "        language: \"af\", \"cn\", etc.\n",
    "        language_index: 0, 1, etc.\n",
    "'''\n",
    "def category_from_output(output):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Get a random input output pair to be used for training \n",
    "Refer the tutorial in the spec\n",
    "'''\n",
    "def random_training_pair(X, y):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: a list of class labels as integers\n",
    "'''\n",
    "def predict(model, X, y):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Input: trained model, a list of words, a list of class labels as integers\n",
    "Output: The accuracy of the given model on the given input X and target y\n",
    "'''\n",
    "def calculateAccuracy(model, X, y):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Train the model for one epoch/one training word.\n",
    "Ensure that it runs within 3 seconds.\n",
    "Input: X and y are lists of words as strings and classes as integers respectively\n",
    "Returns: You may return anything\n",
    "'''\n",
    "def trainOneEpoch(model, criterion, optimizer, X, y):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Use this to train and save your classification model. \n",
    "Save your model with the filename \"model_classify\"\n",
    "'''\n",
    "def run():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NbOusBLKPsrx"
   },
   "outputs": [],
   "source": [
    "#models.py\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "Please add default values for all the parameters of __init__.\n",
    "'''\n",
    "class CharRNNClassify(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        pass\n",
    "\n",
    "    def init_hidden(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation and Analysis (80 marks)\n",
    "\n",
    "Complete the following analysis on the city names dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write code to output accuracy on the validation set (10 marks).  Use a confusion matrix plot to support your answer (10 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Periodically compute the loss on the validation set, and create a plot with the training and validation loss as training progresses (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Experiment with the learning rate. You can try a few different learning rates and observe how this affects the loss. Another common practice is to drop the learning rate when the loss has plateaued. Use plots to explain your experiments and their effects on the loss (20 marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Experiment with the size of the hidden layer or the model architecture How does this affect validation accuracy (20 marks)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw6_skeleton.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
