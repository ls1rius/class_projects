{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from xml.dom.minidom import parse\n",
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = [\"__background__\", \"person\", \"bicycle\", \"car\", \"motorbike\", \"bus\"]\n",
    "label2idx = {label:idx for idx, label in enumerate(idx2label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(img_name_list, data_dir = \"./data/Image/\"):\n",
    "    image_data = dict()\n",
    "    for image_file in img_name_list:\n",
    "        image_filename = os.path.join(data_dir, image_file + \".png\")\n",
    "        image_data[image_file] = torch.Tensor(cv2.imread(image_filename)).permute(2,0,1)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_data(annotations_list, data_dir = \"./data/Annotations/\"):\n",
    "    annotations_data = dict()\n",
    "    for annotations in annotations_list:\n",
    "        domTree = parse(os.path.join(data_dir, annotations+\".xml\"))\n",
    "        rootNode = domTree.documentElement\n",
    "        obj_list = rootNode.getElementsByTagName(\"object\")\n",
    "        label_list = []\n",
    "        boxes_list = []\n",
    "        for obj in obj_list:\n",
    "            label_list.append(int(label2idx[obj.getElementsByTagName(\"name\")[0].firstChild.data]))\n",
    "            boxes_list.append([\n",
    "                    float(obj.getElementsByTagName(\"bndbox\")[0].getElementsByTagName(\"xmin\")[0].firstChild.data),\n",
    "                    float(obj.getElementsByTagName(\"bndbox\")[0].getElementsByTagName(\"ymin\")[0].firstChild.data),\n",
    "                    float(obj.getElementsByTagName(\"bndbox\")[0].getElementsByTagName(\"xmax\")[0].firstChild.data),\n",
    "                    float(obj.getElementsByTagName(\"bndbox\")[0].getElementsByTagName(\"ymax\")[0].firstChild.data)\n",
    "                ])\n",
    "        annotations_data[(rootNode.getElementsByTagName(\"filename\")[0].firstChild.data).split(\".png\")[0]] = {\"boxes\":torch.Tensor(boxes_list),\"labels\":torch.LongTensor(label_list)}\n",
    "    return annotations_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_name_list(data_dir = \"./data/train.txt\"):\n",
    "    with open(data_dir, \"r\") as f:\n",
    "        img_name_list = f.readlines()\n",
    "    f.close()\n",
    "    img_name_list = [img_name.strip() for img_name in img_name_list]\n",
    "    return img_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_list_filepath = \"./data/train.txt\"):\n",
    "    data = []\n",
    "    img_name_list = get_img_name_list(data_list_filepath)\n",
    "    image_data = get_image_data(img_name_list)\n",
    "    annotations_data = get_annotations_data(img_name_list)\n",
    "    for img_name in img_name_list:\n",
    "\n",
    "        if not image_data.__contains__(img_name):\n",
    "#             print(img_name)\n",
    "            continue\n",
    "\n",
    "        if not annotations_data.__contains__(img_name):\n",
    "#             print(img_name)\n",
    "            continue\n",
    "        \n",
    "        data.append([image_data[img_name], annotations_data[img_name]])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(all_data, batch_size = 64):\n",
    "    batches = []\n",
    "    idx = 0\n",
    "    random.shuffle(all_data)\n",
    "    size = len(all_data)\n",
    "    while idx < size:\n",
    "        batches.append(np.array(all_data[idx:idx + batch_size]).transpose(1, 0))\n",
    "        idx += batch_size\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_train_test(data_dir=\"./data\", split_rate=0.05):\n",
    "    with open(os.path.join(data_dir, \"all.txt\"), \"r\") as f:\n",
    "        img_name_list = f.readlines()\n",
    "    f.close()\n",
    "    img_name_list = [img_name.strip() for img_name in img_name_list]\n",
    "    \n",
    "    random.shuffle(img_name_list)\n",
    "    \n",
    "    split_rate = 1 - split_rate\n",
    "    img_name_list_len = len(img_name_list)\n",
    "    img_train_list = img_name_list[:int(img_name_list_len*split_rate)]\n",
    "    img_test_list = img_name_list[int(img_name_list_len*split_rate):]\n",
    "    \n",
    "    with open(os.path.join(data_dir, \"train.txt\"), \"w\") as f:\n",
    "        for item in img_train_list:\n",
    "            f.write(item+\"\\n\")\n",
    "    f.close()\n",
    "        \n",
    "    with open(os.path.join(data_dir, \"test.txt\"), \"w\") as f:\n",
    "        for item in img_test_list:\n",
    "            f.write(item+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writelog(img_name, boxes, labels, scores, data_dir = \"./data/pt/\", threshold = 0):\n",
    "    data_len = len(scores)\n",
    "    with open(os.path.join(data_dir, img_name + \".txt\"), \"w\") as f:\n",
    "        for i in range(data_len):\n",
    "            if scores[i] > threshold :\n",
    "                f.write(\"{} {} {} {} {}\\n\".format(labels[i], boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IOU(rec1,rec2):\n",
    "    #rec: rectangle, [xmin ymin xmax ymax]\n",
    "    #return IoU of rec1 and rec2\n",
    "    width=max(0,min(rec1[2],rec2[2])-max(rec1[0],rec2[0]))\n",
    "    hight=max(0,min(rec1[3],rec2[3])-max(rec1[1],rec2[1]))\n",
    "    inter=width*hight\n",
    "    union=(rec1[3]-rec1[1])*(rec1[2]-rec1[0])+(rec2[3]-rec2[1])*(rec2[2]-rec2[0])-inter\n",
    "    return inter/union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_boxes, pred_labels, gt_boxes, gt_labels):\n",
    "    pred_len = len(pred_boxes)\n",
    "    gt_len = len(gt_boxes)\n",
    "    count = 0\n",
    "    match = np.zeros(gt_len)\n",
    "    for i in range(pred_len):\n",
    "        for j in range(gt_len):\n",
    "            if compute_IOU(pred_boxes[i], gt_boxes[j]) > 0.5 and pred_labels[i] == gt_labels[j] and match[j] == 0:\n",
    "                count += 1\n",
    "                match[j] = 1\n",
    "                break\n",
    "    num_correct = count\n",
    "    num_error = pred_len - count\n",
    "    num_miss = gt_len - count\n",
    "#     print('correct: {}, error: {}, miss: {}'.format(num_correct,num_error,num_miss))\n",
    "    \n",
    "    return num_correct, num_error, num_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_nobatch(img_name_list, image_data, annotations_data):\n",
    "#     model = torch.load(\"best_model.pt\", map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_error = 0 \n",
    "    num_miss = 0\n",
    "    \n",
    "    for img_name in img_name_list:\n",
    "        if not image_data.__contains__(img_name):\n",
    "    #             print(img_name)\n",
    "            continue\n",
    "\n",
    "        if not annotations_data.__contains__(img_name):\n",
    "    #             print(img_name)\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_data = model([image_data[img_name].cuda()])\n",
    "            \n",
    "        tmp_num_correct, tmp_num_error, tmp_num_miss = evaluate(pred_data[0][\"boxes\"].cpu(), pred_data[0][\"labels\"].cpu(), \n",
    "                                                                annotations_data[img_name][\"boxes\"], annotations_data[img_name][\"labels\"])\n",
    "        num_correct = num_correct + tmp_num_correct\n",
    "        num_error = num_error + tmp_num_error\n",
    "        num_miss = num_miss + tmp_num_miss\n",
    "        \n",
    "#         writelog(img_name = img_name, boxes = pred_data[0][\"boxes\"].cpu(), labels = pred_data[0][\"labels\"].cpu(), scores = pred_data[0][\"scores\"].cpu())\n",
    "        \n",
    "    mAP=num_correct/(num_correct+num_error)\n",
    "    mAR=num_correct/(num_correct+num_miss)\n",
    "    F_measure=2*mAP*mAR/(mAP+mAR)\n",
    "    print('mAP={}\\n mAR={}\\n F-measure={}'.format(mAP,mAR,F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(pred_boxes, pred_labels, gt_boxes, gt_labels):\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_error = 0 \n",
    "    num_miss = 0\n",
    "    \n",
    "    eval_len = len(pred_boxes)\n",
    "    for i in range(eval_len):\n",
    "        tmp_num_correct, tmp_num_error, tmp_num_miss = evaluate(pred_boxes[i], pred_labels[i], gt_boxes[i], gt_labels[i])\n",
    "        num_correct = num_correct + tmp_num_correct\n",
    "        num_error = num_error + tmp_num_error\n",
    "        num_miss = num_miss + tmp_num_miss\n",
    "        \n",
    "    mAP=num_correct/(num_correct+num_error)\n",
    "    mAR=num_correct/(num_correct+num_miss)\n",
    "    F_measure=2*mAP*mAR/(mAP+mAR)\n",
    "    print('mAP={}\\n mAR={}\\n F-measure={}'.format(mAP,mAR,F_measure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(img_name_list, image_data, annotations_data):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    pred_img = []\n",
    "    gt_data = []\n",
    "    for img_name in img_name_list:\n",
    "        if not image_data.__contains__(img_name):\n",
    "    #             print(img_name)\n",
    "            continue\n",
    "\n",
    "        if not annotations_data.__contains__(img_name):\n",
    "    #             print(img_name)\n",
    "            continue\n",
    "\n",
    "        pred_img.append(image_data[img_name])\n",
    "        gt_data.append(annotations_data[img_name])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_data = model(pred_img)\n",
    "\n",
    "    pred_eval_boxes = []\n",
    "    pred_eval_labels = []\n",
    "    gt_eval_boxes = []\n",
    "    gt_eval_labels = []\n",
    "\n",
    "    for item in pred_data:\n",
    "        pred_eval_boxes.append(item[\"boxes\"])\n",
    "        pred_eval_labels.append(item[\"labels\"])\n",
    "        # wirte predict log\n",
    "#         writelog(img_name = img_name, boxes = item[\"boxes\"], labels = item[\"labels\"], scores = item[\"scores\"])\n",
    "\n",
    "    for item in gt_data:\n",
    "        gt_eval_boxes.append(item[\"boxes\"])\n",
    "        gt_eval_labels.append(item[\"labels\"])\n",
    "\n",
    "    evaluate_all(pred_eval_boxes, pred_eval_labels, gt_eval_boxes, gt_eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, batch, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    images, targets = batch\n",
    "    images = list(image.cuda() for image in images)\n",
    "    targets = [{k: v.cuda() for k, v in t.items()} for t in targets]\n",
    "    \n",
    "    loss_dict = model(images, targets)\n",
    "    losses = sum(loss for loss in loss_dict.values())\n",
    "    optimizer.zero_grad()\n",
    "    losses.backward()\n",
    "    optimizer.step()\n",
    "    return losses.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, batches, optimizer, scheduler):\n",
    "    \n",
    "    minn_losses = np.inf\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        print(\"epoch:\", epoch + 1)\n",
    "        losses = 0\n",
    "        \n",
    "        for batch in batches:\n",
    "            loss = train_one_epoch(model, batch, optimizer)\n",
    "            losses += loss\n",
    "                \n",
    "        cur_losses = losses/len(batches)\n",
    "        scheduler.step(cur_losses)\n",
    "        #         evaluate_model_nobatch(test_img_name_list, test_image_data, test_annotations_data)\n",
    "        print(\"time cost:\", time.time() - start_time)\n",
    "        print(\"losses:\", cur_losses)\n",
    "        \n",
    "        if(minn_losses>cur_losses):\n",
    "            torch.save(model, \"./best_model_all.pt\")\n",
    "            minn_losses=cur_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_train_test()\n",
    "train_data = get_data(\"./data/all.txt\")\n",
    "batches = make_batch(train_data, batch_size = 4)\n",
    "\n",
    "# test_img_name_list = get_img_name_list(\"./data/test.txt\")\n",
    "# test_image_data = get_image_data(test_img_name_list)\n",
    "# test_annotations_data = get_annotations_data(test_img_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained = False, pretrained_backbone = True, num_classes = len(idx2label))\n",
    "# model = fasterrcnn_resnet50_fpn(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode = \"min\", patience = 2, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "model.cuda()\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "time cost: 527.0271625518799\n",
      "losses: 0.024692895339336725\n",
      "epoch: 2\n",
      "time cost: 518.4622974395752\n",
      "losses: 0.024786996607547136\n",
      "epoch: 3\n",
      "time cost: 518.3007614612579\n",
      "losses: 0.024583294268128945\n",
      "epoch: 4\n",
      "time cost: 517.1050350666046\n",
      "losses: 0.024562149716135333\n",
      "epoch: 5\n",
      "time cost: 517.0489892959595\n",
      "losses: 0.024441821734446798\n",
      "epoch: 6\n",
      "time cost: 517.2553100585938\n",
      "losses: 0.024583944907499992\n",
      "epoch: 7\n",
      "time cost: 516.312757730484\n",
      "losses: 0.024697236533449983\n",
      "epoch: 8\n",
      "Epoch     8: reducing learning rate of group 0 to 1.0000e-07.\n",
      "time cost: 517.194233417511\n",
      "losses: 0.024693996057570944\n",
      "epoch: 9\n",
      "time cost: 517.1616199016571\n",
      "losses: 0.024521582700572486\n",
      "epoch: 10\n",
      "time cost: 517.1106107234955\n",
      "losses: 0.024563755211204994\n",
      "epoch: 11\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-08.\n",
      "time cost: 516.9329569339752\n",
      "losses: 0.02477929790557878\n",
      "epoch: 12\n",
      "time cost: 516.8449988365173\n",
      "losses: 0.024742486365263917\n",
      "epoch: 13\n",
      "time cost: 516.6490831375122\n",
      "losses: 0.024723902883827458\n",
      "epoch: 14\n",
      "time cost: 517.0729892253876\n",
      "losses: 0.02482102771303047\n",
      "epoch: 15\n",
      "time cost: 517.3661313056946\n",
      "losses: 0.024650945655526814\n",
      "epoch: 16\n",
      "time cost: 517.1932854652405\n",
      "losses: 0.024716277933418216\n",
      "epoch: 17\n",
      "time cost: 517.1828963756561\n",
      "losses: 0.02470535849568502\n",
      "epoch: 18\n",
      "time cost: 516.9750468730927\n",
      "losses: 0.02466437833040057\n",
      "epoch: 19\n",
      "time cost: 517.2878105640411\n",
      "losses: 0.024586221602585508\n",
      "epoch: 20\n",
      "time cost: 517.0032815933228\n",
      "losses: 0.02452942558525002\n",
      "epoch: 21\n",
      "time cost: 517.0076146125793\n",
      "losses: 0.024757140159333182\n",
      "epoch: 22\n",
      "time cost: 517.2269177436829\n",
      "losses: 0.024715530033293204\n",
      "epoch: 23\n",
      "time cost: 516.8768792152405\n",
      "losses: 0.024645663635855023\n",
      "epoch: 24\n",
      "time cost: 517.3658628463745\n",
      "losses: 0.024500731378075843\n",
      "epoch: 25\n",
      "time cost: 517.2463526725769\n",
      "losses: 0.024610759890212355\n",
      "epoch: 26\n",
      "time cost: 517.3482024669647\n",
      "losses: 0.024660534004298903\n",
      "epoch: 27\n",
      "time cost: 517.2477512359619\n",
      "losses: 0.024589446462061015\n",
      "epoch: 28\n",
      "time cost: 517.0738098621368\n",
      "losses: 0.024606951673918107\n",
      "epoch: 29\n",
      "time cost: 517.3342275619507\n",
      "losses: 0.02473359204515746\n",
      "epoch: 30\n",
      "time cost: 516.5067102909088\n",
      "losses: 0.02476865009290816\n",
      "epoch: 31\n",
      "time cost: 516.5979754924774\n",
      "losses: 0.02455985253602113\n",
      "epoch: 32\n",
      "time cost: 517.415958404541\n",
      "losses: 0.02456241842973805\n",
      "epoch: 33\n",
      "time cost: 517.3246924877167\n",
      "losses: 0.024577619735953633\n",
      "epoch: 34\n",
      "time cost: 517.5806143283844\n",
      "losses: 0.02463944260971879\n",
      "epoch: 35\n",
      "time cost: 517.0282907485962\n",
      "losses: 0.024645800071501415\n",
      "epoch: 36\n",
      "time cost: 516.0213057994843\n",
      "losses: 0.02459211494770755\n",
      "epoch: 37\n",
      "time cost: 517.6180949211121\n",
      "losses: 0.024694293365552487\n",
      "epoch: 38\n",
      "time cost: 517.1547186374664\n",
      "losses: 0.024642907378080954\n",
      "epoch: 39\n",
      "time cost: 517.024751663208\n",
      "losses: 0.02468943671813428\n",
      "epoch: 40\n",
      "time cost: 516.855836391449\n",
      "losses: 0.024603952720468406\n",
      "epoch: 41\n",
      "time cost: 516.5814690589905\n",
      "losses: 0.02473701248476655\n",
      "epoch: 42\n",
      "time cost: 517.235732793808\n",
      "losses: 0.024610671236056293\n",
      "epoch: 43\n",
      "time cost: 517.3084535598755\n",
      "losses: 0.02468846493375747\n",
      "epoch: 44\n",
      "time cost: 516.5402810573578\n",
      "losses: 0.024679068382637996\n",
      "epoch: 45\n",
      "time cost: 516.2655410766602\n",
      "losses: 0.02468545319855152\n",
      "epoch: 46\n",
      "time cost: 516.5818910598755\n",
      "losses: 0.024617326719627044\n",
      "epoch: 47\n",
      "time cost: 517.2565159797668\n",
      "losses: 0.024632821218967284\n",
      "epoch: 48\n",
      "time cost: 517.3422610759735\n",
      "losses: 0.0247104998389862\n",
      "epoch: 49\n",
      "time cost: 516.996746301651\n",
      "losses: 0.024689522284951217\n",
      "epoch: 50\n",
      "time cost: 516.9770393371582\n",
      "losses: 0.024580642080866758\n",
      "epoch: 51\n",
      "time cost: 516.8323919773102\n",
      "losses: 0.024677333371514665\n",
      "epoch: 52\n",
      "time cost: 517.3242897987366\n",
      "losses: 0.02464535938554806\n",
      "epoch: 53\n",
      "time cost: 516.5818331241608\n",
      "losses: 0.024657140188024427\n",
      "epoch: 54\n",
      "time cost: 516.7746074199677\n",
      "losses: 0.024515068164011052\n",
      "epoch: 55\n",
      "time cost: 516.5177664756775\n",
      "losses: 0.024615484498965747\n",
      "epoch: 56\n",
      "time cost: 517.2327938079834\n",
      "losses: 0.02454999883186344\n",
      "epoch: 57\n",
      "time cost: 517.0217714309692\n",
      "losses: 0.024492648091331844\n",
      "epoch: 58\n",
      "time cost: 516.9972581863403\n",
      "losses: 0.024694793715016324\n",
      "epoch: 59\n",
      "time cost: 517.2743258476257\n",
      "losses: 0.02457391151790828\n",
      "epoch: 60\n",
      "time cost: 516.6388564109802\n",
      "losses: 0.02463995630494898\n",
      "epoch: 61\n",
      "time cost: 517.1881799697876\n",
      "losses: 0.02474635641592127\n",
      "epoch: 62\n",
      "time cost: 516.636908531189\n",
      "losses: 0.02459703577071704\n",
      "epoch: 63\n",
      "time cost: 517.0597560405731\n",
      "losses: 0.024390544097933762\n",
      "epoch: 64\n",
      "time cost: 516.7735879421234\n",
      "losses: 0.0247151025605387\n",
      "epoch: 65\n",
      "time cost: 517.5633792877197\n",
      "losses: 0.024714544523872995\n",
      "epoch: 66\n",
      "time cost: 517.1546585559845\n",
      "losses: 0.0245140218561207\n",
      "epoch: 67\n",
      "time cost: 517.2716901302338\n",
      "losses: 0.02476744926730812\n",
      "epoch: 68\n",
      "time cost: 517.0585916042328\n",
      "losses: 0.024706638285091946\n",
      "epoch: 69\n",
      "time cost: 517.364574432373\n",
      "losses: 0.024669742910430708\n",
      "epoch: 70\n",
      "time cost: 516.93927526474\n",
      "losses: 0.024550937021386648\n",
      "epoch: 71\n",
      "time cost: 517.3010673522949\n",
      "losses: 0.02462417131193166\n",
      "epoch: 72\n",
      "time cost: 516.922933101654\n",
      "losses: 0.02463332899053603\n",
      "epoch: 73\n",
      "time cost: 517.1742033958435\n",
      "losses: 0.02467313282074979\n",
      "epoch: 74\n",
      "time cost: 517.1981213092804\n",
      "losses: 0.024530134788587045\n",
      "epoch: 75\n",
      "time cost: 517.7262637615204\n",
      "losses: 0.02464247721592912\n",
      "epoch: 76\n",
      "time cost: 516.872670173645\n",
      "losses: 0.024672805489819087\n",
      "epoch: 77\n",
      "time cost: 517.1932680606842\n",
      "losses: 0.024564861834914502\n",
      "epoch: 78\n",
      "time cost: 517.7424886226654\n",
      "losses: 0.02464297407700126\n",
      "epoch: 79\n",
      "time cost: 517.4858400821686\n",
      "losses: 0.02465582522491849\n",
      "epoch: 80\n",
      "time cost: 517.1639862060547\n",
      "losses: 0.024541634196685463\n",
      "epoch: 81\n",
      "time cost: 517.0312411785126\n",
      "losses: 0.02467967272269035\n",
      "epoch: 82\n",
      "time cost: 517.3351106643677\n",
      "losses: 0.02472086943411302\n",
      "epoch: 83\n",
      "time cost: 517.2204215526581\n",
      "losses: 0.02463082249950185\n",
      "epoch: 84\n",
      "time cost: 518.8797397613525\n",
      "losses: 0.02469121704748109\n",
      "epoch: 85\n",
      "time cost: 518.8660726547241\n",
      "losses: 0.024697033994240572\n",
      "epoch: 86\n",
      "time cost: 516.7282421588898\n",
      "losses: 0.024506606508567088\n",
      "epoch: 87\n",
      "time cost: 517.1917850971222\n",
      "losses: 0.024727551016491385\n",
      "epoch: 88\n",
      "time cost: 517.0675950050354\n",
      "losses: 0.024625393019784298\n",
      "epoch: 89\n",
      "time cost: 517.3807735443115\n",
      "losses: 0.024662725049054743\n",
      "epoch: 90\n",
      "time cost: 516.940279006958\n",
      "losses: 0.024616144050270673\n",
      "epoch: 91\n",
      "time cost: 516.562251329422\n",
      "losses: 0.02474431916071104\n",
      "epoch: 92\n",
      "time cost: 517.2095046043396\n",
      "losses: 0.02463003516389595\n",
      "epoch: 93\n",
      "time cost: 517.516476392746\n",
      "losses: 0.024610817228766485\n",
      "epoch: 94\n",
      "time cost: 517.0804190635681\n",
      "losses: 0.024601976786340986\n",
      "epoch: 95\n",
      "time cost: 517.0861372947693\n",
      "losses: 0.024636554895236872\n",
      "epoch: 96\n",
      "time cost: 517.28653216362\n",
      "losses: 0.024533771910730515\n",
      "epoch: 97\n",
      "time cost: 517.7116868495941\n",
      "losses: 0.02444779305175169\n",
      "epoch: 98\n",
      "time cost: 517.2025146484375\n",
      "losses: 0.024604897954973094\n",
      "epoch: 99\n",
      "time cost: 517.5405828952789\n",
      "losses: 0.024657928193407275\n",
      "epoch: 100\n",
      "time cost: 517.270973443985\n",
      "losses: 0.024677620333488283\n",
      "epoch: 101\n",
      "time cost: 517.767181634903\n",
      "losses: 0.02457589362384244\n",
      "epoch: 102\n",
      "time cost: 517.2174026966095\n",
      "losses: 0.02471798439108157\n",
      "epoch: 103\n",
      "time cost: 517.3829038143158\n",
      "losses: 0.024512735004264014\n",
      "epoch: 104\n",
      "time cost: 517.8589818477631\n",
      "losses: 0.024540943433152548\n",
      "epoch: 105\n",
      "time cost: 517.6008694171906\n",
      "losses: 0.02466623112463602\n",
      "epoch: 106\n",
      "time cost: 518.2746434211731\n",
      "losses: 0.024606438927957358\n",
      "epoch: 107\n",
      "time cost: 518.1405453681946\n",
      "losses: 0.02467026930581874\n",
      "epoch: 108\n",
      "time cost: 518.1095261573792\n",
      "losses: 0.02452007337819827\n",
      "epoch: 109\n",
      "time cost: 575.909069776535\n",
      "losses: 0.02459511027349789\n",
      "epoch: 110\n",
      "time cost: 595.2734525203705\n",
      "losses: 0.024493089367617363\n",
      "epoch: 111\n",
      "time cost: 596.0063779354095\n",
      "losses: 0.02458872521709639\n",
      "epoch: 112\n",
      "time cost: 597.0664556026459\n",
      "losses: 0.02459457525189005\n",
      "epoch: 113\n",
      "time cost: 595.3856906890869\n",
      "losses: 0.02476853147777944\n",
      "epoch: 114\n",
      "time cost: 597.294415473938\n",
      "losses: 0.024705850671190015\n",
      "epoch: 115\n",
      "time cost: 596.6086096763611\n",
      "losses: 0.02472093786693964\n",
      "epoch: 116\n",
      "time cost: 595.2322986125946\n",
      "losses: 0.024730830426057008\n",
      "epoch: 117\n",
      "time cost: 595.8595588207245\n",
      "losses: 0.0246271285420343\n",
      "epoch: 118\n",
      "time cost: 594.9129152297974\n",
      "losses: 0.02444245934439488\n",
      "epoch: 119\n",
      "time cost: 593.808055639267\n",
      "losses: 0.02470078654319262\n",
      "epoch: 120\n",
      "time cost: 595.7474629878998\n",
      "losses: 0.02464845780625878\n",
      "epoch: 121\n",
      "time cost: 595.8851256370544\n",
      "losses: 0.02453145735637732\n",
      "epoch: 122\n",
      "time cost: 592.4971809387207\n",
      "losses: 0.02457197701686731\n",
      "epoch: 123\n",
      "time cost: 593.6885962486267\n",
      "losses: 0.024572025384621853\n",
      "epoch: 124\n",
      "time cost: 592.5181634426117\n",
      "losses: 0.02458873973491258\n",
      "epoch: 125\n",
      "time cost: 592.504150390625\n",
      "losses: 0.024659358574707302\n",
      "epoch: 126\n",
      "time cost: 587.9159688949585\n",
      "losses: 0.02458114747124564\n",
      "epoch: 127\n",
      "time cost: 576.8795330524445\n",
      "losses: 0.024635216612454967\n",
      "epoch: 128\n",
      "time cost: 559.0355830192566\n",
      "losses: 0.024679002356366133\n",
      "epoch: 129\n",
      "time cost: 542.2945318222046\n",
      "losses: 0.024519888225431722\n",
      "epoch: 130\n",
      "time cost: 560.6183204650879\n",
      "losses: 0.024533167815473378\n",
      "epoch: 131\n",
      "time cost: 606.3737814426422\n",
      "losses: 0.024495622458535593\n",
      "epoch: 132\n",
      "time cost: 610.223269701004\n",
      "losses: 0.024637798594697575\n",
      "epoch: 133\n",
      "time cost: 604.3112554550171\n",
      "losses: 0.02457565669365656\n",
      "epoch: 134\n",
      "time cost: 605.7558608055115\n",
      "losses: 0.024712580421993095\n",
      "epoch: 135\n",
      "time cost: 611.666919708252\n",
      "losses: 0.024729638841895257\n",
      "epoch: 136\n",
      "time cost: 615.5998504161835\n",
      "losses: 0.024522256375819767\n",
      "epoch: 137\n",
      "time cost: 616.3888192176819\n",
      "losses: 0.024579255792139078\n",
      "epoch: 138\n",
      "time cost: 619.0506720542908\n",
      "losses: 0.024601862672524948\n",
      "epoch: 139\n",
      "time cost: 618.7828071117401\n",
      "losses: 0.024626046384446407\n",
      "epoch: 140\n",
      "time cost: 615.7608211040497\n",
      "losses: 0.02461548943076386\n",
      "epoch: 141\n",
      "time cost: 617.0971810817719\n",
      "losses: 0.02459598422090677\n",
      "epoch: 142\n",
      "time cost: 614.962641954422\n",
      "losses: 0.024622194999484356\n",
      "epoch: 143\n",
      "time cost: 612.6357102394104\n",
      "losses: 0.024551837739055137\n",
      "epoch: 144\n",
      "time cost: 621.4910855293274\n",
      "losses: 0.024571794210832647\n",
      "epoch: 145\n",
      "time cost: 605.3197636604309\n",
      "losses: 0.024489347879915573\n",
      "epoch: 146\n",
      "time cost: 607.2965786457062\n",
      "losses: 0.024726892042836176\n",
      "epoch: 147\n",
      "time cost: 603.2347893714905\n",
      "losses: 0.024717756614513992\n",
      "epoch: 148\n",
      "time cost: 602.0233523845673\n",
      "losses: 0.024714229223323184\n",
      "epoch: 149\n",
      "time cost: 602.3123795986176\n",
      "losses: 0.024664342302430847\n",
      "epoch: 150\n",
      "time cost: 603.3973953723907\n",
      "losses: 0.024566174101683658\n",
      "epoch: 151\n",
      "time cost: 593.1486768722534\n",
      "losses: 0.02455735513591088\n",
      "epoch: 152\n",
      "time cost: 589.4231531620026\n",
      "losses: 0.024518588721993372\n",
      "epoch: 153\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, batches, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python376",
   "language": "python",
   "name": "python376"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
